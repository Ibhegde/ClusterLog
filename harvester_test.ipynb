{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterlogs Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from clusterlogs import pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data from file and create pandas DataFrame with index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('samples/harvester_errors24.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/maria/cernbox/LogsClusterization/Harvester/data_sample.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5726, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CERN_central_A|118722113</td>\n",
       "      <td>Condor HoldReason: None ; Condor RemoveReason:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CERN_central_B|133202736</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>CERN_central_B|133202747</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>CERN_central_B|133201846</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CERN_central_B|133201823</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        id  \\\n",
       "0           0  CERN_central_A|118722113   \n",
       "1           1  CERN_central_B|133202736   \n",
       "2           2  CERN_central_B|133202747   \n",
       "3           3  CERN_central_B|133201846   \n",
       "4           4  CERN_central_B|133201823   \n",
       "\n",
       "                                             message  \n",
       "0  Condor HoldReason: None ; Condor RemoveReason:...  \n",
       "1         Payload execution error: returned non-zero  \n",
       "2         Payload execution error: returned non-zero  \n",
       "3         Payload execution error: returned non-zero  \n",
       "4         Payload execution error: returned non-zero  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'message'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(df['message'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Execute clusterization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pipeline.Chain(df, target, mode='process', model_name='harvester_test.model', matching_accuracy=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization finished\n",
      "Found 55 equal groups\n",
      "Matching Clusterization!\n",
      "Postprocessed with 31 clusters\n"
     ]
    }
   ],
   "source": [
    "cluster.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: Maximum number of jobs already in queue MSG=total number of jobs in queue exceeds the queue limit: user atlasp@lapp-ce01.in2p3.fr, queue atlasMC8-',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: Maximum number of jobs already in queue MSG=total number of jobs in queue exceeds the queue limit: user atlasp@lapp-ce03.in2p3.fr, queue atlasMC8-',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: submit error (Maximum number of jobs already in queue MSG=total number of jobs in queue exceeds the queue limit: user atlasprodusr01@localhost, qu',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[jobRegister] ErrorCode=[0] Description=[The CREAM service cannot accept jobs at the moment] FaultCause=[Submissions are disabled!] Timestamp=[Sat 22 Feb 2020 12:50:12] ; Worker canceled',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[jobRegister] ErrorCode=[0] Description=[The CREAM service cannot accept jobs at the moment] FaultCause=[Threshold for Disk Usage: 95% => Detected value for Partition / : 95%\\\\n\\\\n] Timesta',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: Received NULL fault; the error is due to another cause: FaultString=[connection error] - FaultCode=[SOAP-ENV:Client] - FaultSubCode=[SOAP-ENV:Client] - FaultDetail=[Connection timed out] ; Worker c',\n",
       "       'Condor HoldReason: CREAM error: Cannot move ISB (retry_copy ${globus_transfer_cmd} gsiftp:/calc2.t1.grid.kiae.ru/var/cream_sandbox/atlasprd/CN_Robot__ATLAS_Pilot1_CN_614260_CN_atlpilo1_OU_Users_OU_Organic_Units_DC_cern_DC_ch_atlas_Role_production_Capabili',\n",
       "       'Condor HoldReason: CREAM error: Cannot move ISB (retry_copy ${globus_transfer_cmd} gsiftp:/calc3.t1.grid.kiae.ru/var/cream_sandbox/atlasprd/CN_Robot__ATLAS_Pilot1_CN_614260_CN_atlpilo1_OU_Users_OU_Organic_Units_DC_cern_DC_ch_atlas_Role_production_Capabili',\n",
       "       'Condor HoldReason: CREAM error: Job has been terminated (got｟*｠) ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: Job has been terminated (got SIGTERM); Cannot upload file:/home/gridpools/atlaspilot0071/home_cream_668136194/CREAM668136194/grid.17552583.8.out into gsiftp:/calc2.t1.grid.kiae.ru/var/cream_sandbox/atlaspilot/CN_Robot__AT',\n",
       "       'Condor HoldReason: CREAM error: Job has been terminated (got SIGTERM); reason=-10 ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: Job has been terminated (got SIGXCPU); reason=255 ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /sandboxes/atlas/CN_Robot__ATLAS_Pilot1_CN_614260_CN_atlpil',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /var/cream_sandbox/atlasprd/CN_Robot__ATLAS_Pilot1_CN_61426',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /var/cream_sandbox/pilatlas/CN_Robot__ATLAS_Pilot1_CN_61426',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /var/cream_sandbox/prdatlas/CN_Robot__ATLAS_Pilot1_CN_61426',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : callback failed. 500-globus_xio: Unable to connect to 188.185.66.87:31269 500-globus_xio: System error in connect: Connection',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_gridftp_server_file.c:globus_l_gfs_file_send:3315: 500-globus_l_gfs_file_open failed. 500-globus_gridftp_server_file.c',\n",
       "       'Condor HoldReason: CREAM error: reason=-10',\n",
       "       'Condor HoldReason: CREAM error: reason=-10 ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: reason=0',\n",
       "       'Condor HoldReason: CREAM error: reason=0 ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: reason=126; /var/lib/torque/mom_priv/jobs/446406.ce.physics.science.az.SC: ./CREAM362102614_jobWrapper.sh: /bin/sh: bad interpreter: Text file busy ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: Stream closed ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM_Delegate Error: Received NULL fault; the error is due to another cause: FaultString=[connection error] - FaultCode=[SOAP-ENV:Client] - FaultSubCode=[SOAP-ENV:Client] - FaultDetail=[Connection timed out] ; Worker canceled by harves',\n",
       "       'Condor HoldReason: Error parsing classad or job not found ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: Failed to get expiration time of proxy: unable to read proxy file ; Worker canceled by harvester due to held too long or not found',\n",
       "       \"Condor HoldReason: HTCondor-CE held job due to no matching routes, route job limit, or route failure threshold; see 'HTCondor-CE Troubleshooting Guide' ; Worker canceled by harvester due to held too long or not found\",\n",
       "       'Condor HoldReason: Job not found ; Worker canceled by harvester due to held too long or not found',\n",
       "       \"Condor HoldReason: None ; Condor RemoveReason: The job attribute PeriodicRemove expression '(JobStatus = 2 & (CurrentTime - EnteredCurrentStatus) > 604800)' evaluated to TRUE\",\n",
       "       'Condor HoldReason: None ; Condor RemoveReason: removed by SYSTEM_PERIODIC_REMOVE due to job restarted undesirably.',\n",
       "       'Condor HoldReason: None ; Condor RemoveReason: Python-initiated action. (by user atlpan)',\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '( NumJobStarts >= 1 & JobStatus = 1 )' evaluated to TRUE ; Worker canceled by harvester due to held too long or not found\",\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '(x509userproxysubject =?= undefined) | (x509UserProxyExpiration =?= undefined) | (time() > x509UserProxyExpiration) & JobStatus =!= 3 & JobStatus =!= 4) | (RoutedBy =?= null & JobU\",\n",
       "       'Condor HoldReason: submission command failed (exit code = 1) (stdout:) (stderr:sbatch: error: Batch job submission failed: Requested time limit is invalid (missing or exceeds some limit)-Error from sbatch: -) ; Worker canceled by harvester due to held too',\n",
       "       'Condor HoldReason: Unspecified gridmanager error',\n",
       "       'Condor HoldReason: Unspecified gridmanager error ; Condor RemoveReason: Python-initiated action. (by user atlpan)',\n",
       "       'Condor HoldReason: Unspecified gridmanager error ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: NORDUGRID_SUBMIT timed out ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: globus_xio: The GSI XIO driver failed to establish a secure connection. The failure occured during a handshake read. globus_xio: Operation was canceled globus_xio: Operation timed out ; Worker canceled by harvester due to held too long',\n",
       "       'Error reading user generated output file list',\n",
       "       'Failed in data staging: Failed checking source replica root:/fax.mwt2.org:1094/pnfs/uchicago.edu/atlasdatadisk/rucio/mc16_13TeV/｟*｠/｟*｠/DAOD_TOPQ1.17829848.｟*｠: Failed to obtain information about file: Permission denied',\n",
       "       'Failed in data staging: Failed checking source replica root:/fax.mwt2.org:1094/pnfs/uchicago.edu/atlasdatadisk/rucio/mc16_13TeV/｟*｠/｟*｠/DAOD_TOPQ1.17829848.｟*｠: Failed to obtain information about file: Permission denied; Failed in data stag',\n",
       "       'Failed in data staging: Failed to prepare source srm:/srm-atlas.cern.ch:8443/srm/managerv2?SFN=/castor/cern.ch/grid/atlas/atlasdatatape/ddo/DBRelease/v310701/ddo.000001.Atlas.Ideal.DBRelease.v310701/DBRelease-31.7.1.tar.gz: Failed to prepare source: No su',\n",
       "       'Job submission to LRMS failed',\n",
       "       'LRMS error: (-1) Job missing from SLURM',\n",
       "       'LRMS error: (-1) Job was killed by Condor',\n",
       "       'LRMS error: (-1) RemoveReason: Job removed by SYSTEM_PERIODIC_REMOVE due to disk usage exceeding 150 GB.',\n",
       "       'LRMS error: (1) Job failed', 'LRMS error: (271) Job timeout',\n",
       "       'LRMS error: (271) Job was cancelled',\n",
       "       'LRMS error: (271) job killed:｟*｠', 'Unknown error',\n",
       "       '｟*｠ not submitted due to incomplete data of the worker',\n",
       "       'Payload execution error: returned non-zero'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.groups['pattern'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Result: all clusters (big clusters and outliers) - sorted by cluster size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>indices</th>\n",
       "      <th>cluster_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Condor HoldReason:｟*｠:｟*｠ ; Worker canceled by...</td>\n",
       "      <td>[1163, 1661, 1948, 1950, 1951, 1952, 1953, 272...</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Condor HoldReason: HTCondor-CE held job due to...</td>\n",
       "      <td>[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1...</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "      <td>[1, 2, 3, 4, 92, 93, 94, 95, 96, 97, 98, 99, 1...</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Condor HoldReason: CREAM error: BLAH error: su...</td>\n",
       "      <td>[71, 72, 73, 76, 184, 185, 187, 189, 190, 192,...</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Condor HoldReason: None ; Condor RemoveReason:...</td>\n",
       "      <td>[0, 22, 114, 115, 116, 117, 118, 126, 127, 128...</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Condor HoldReason: The system macro SYSTEM_PER...</td>\n",
       "      <td>[217, 218, 248, 249, 250, 251, 252, 253, 254, ...</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>｟*｠ not submitted due to incomplete data of th...</td>\n",
       "      <td>[64, 65, 66, 123, 124, 133, 134, 135, 136, 137...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>LRMS error: (271)｟*｠</td>\n",
       "      <td>[158, 160, 183, 282, 435, 577, 658, 666, 667, ...</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Condor HoldReason: CREAM error: Transfer faile...</td>\n",
       "      <td>[741, 283, 284, 292, 685, 1123, 1345, 1648, 20...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Condor HoldReason: CREAM error: reason=｟*｠</td>\n",
       "      <td>[2371, 5218, 648, 649, 650, 657, 927, 1115, 11...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Condor HoldReason: submission command failed (...</td>\n",
       "      <td>[265, 266, 267, 887, 888, 889, 890, 1302, 1966...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>LRMS error: (1) Job failed</td>\n",
       "      <td>[153, 205, 206, 325, 326, 669, 1664, 1921, 197...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Condor HoldReason: CREAM error: Cannot move IS...</td>\n",
       "      <td>[1092, 1689, 2365, 2588, 3066, 3067, 3492, 364...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Condor HoldReason:｟*｠ error:｟*｠ Error: Receive...</td>\n",
       "      <td>[2070, 2167, 3503, 4057, 4060, 4956, 5339, 538...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Condor HoldReason:｟*｠ ; Condor RemoveReason: P...</td>\n",
       "      <td>[383, 698, 738, 1346, 1429, 1561, 1681, 2335, ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Condor HoldReason: The system macro SYSTEM_PER...</td>\n",
       "      <td>[437, 704, 1348, 1349, 2072, 2354, 2456, 2653,...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>LRMS error: (-1) Job was killed by Condor</td>\n",
       "      <td>[789, 952, 2142, 2143, 2297, 2392, 2393, 2394,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Job submission to LRMS failed</td>\n",
       "      <td>[1882, 1883, 4833, 4834, 5318, 5319, 5704, 571...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Condor HoldReason: Failed to get expiration ti...</td>\n",
       "      <td>[154, 155, 1497, 1498, 2831, 3093, 3094, 3095]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Failed in data staging: Failed checking source...</td>\n",
       "      <td>[350, 2283, 4358, 2282, 2711, 2731]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Error reading user generated output file list</td>\n",
       "      <td>[2160, 2251, 3336, 4326]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Condor HoldReason: CREAM error: CREAM_Job_Regi...</td>\n",
       "      <td>[120, 1762, 3582]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Failed in data staging: Failed to prepare sour...</td>\n",
       "      <td>[129, 915]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Condor HoldReason: Unspecified gridmanager error</td>\n",
       "      <td>[2159, 4700]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Condor HoldReason: globus_xio: The GSI XIO dri...</td>\n",
       "      <td>[992]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Condor HoldReason: CREAM error: Job has been t...</td>\n",
       "      <td>[1662]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>LRMS error: (-1) Job missing from SLURM</td>\n",
       "      <td>[178]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Condor HoldReason: None ; Condor RemoveReason:...</td>\n",
       "      <td>[1733]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>LRMS error: (-1) RemoveReason: Job removed by ...</td>\n",
       "      <td>[5725]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Unknown error</td>\n",
       "      <td>[795]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Condor HoldReason: CREAM error: Transfer faile...</td>\n",
       "      <td>[4229]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pattern  \\\n",
       "4   Condor HoldReason:｟*｠:｟*｠ ; Worker canceled by...   \n",
       "10  Condor HoldReason: HTCondor-CE held job due to...   \n",
       "30         Payload execution error: returned non-zero   \n",
       "0   Condor HoldReason: CREAM error: BLAH error: su...   \n",
       "12  Condor HoldReason: None ; Condor RemoveReason:...   \n",
       "15  Condor HoldReason: The system macro SYSTEM_PER...   \n",
       "29  ｟*｠ not submitted due to incomplete data of th...   \n",
       "27                               LRMS error: (271)｟*｠   \n",
       "6   Condor HoldReason: CREAM error: Transfer faile...   \n",
       "8          Condor HoldReason: CREAM error: reason=｟*｠   \n",
       "16  Condor HoldReason: submission command failed (...   \n",
       "26                         LRMS error: (1) Job failed   \n",
       "3   Condor HoldReason: CREAM error: Cannot move IS...   \n",
       "2   Condor HoldReason:｟*｠ error:｟*｠ Error: Receive...   \n",
       "13  Condor HoldReason:｟*｠ ; Condor RemoveReason: P...   \n",
       "14  Condor HoldReason: The system macro SYSTEM_PER...   \n",
       "24          LRMS error: (-1) Job was killed by Condor   \n",
       "22                      Job submission to LRMS failed   \n",
       "9   Condor HoldReason: Failed to get expiration ti...   \n",
       "20  Failed in data staging: Failed checking source...   \n",
       "19      Error reading user generated output file list   \n",
       "1   Condor HoldReason: CREAM error: CREAM_Job_Regi...   \n",
       "21  Failed in data staging: Failed to prepare sour...   \n",
       "17   Condor HoldReason: Unspecified gridmanager error   \n",
       "18  Condor HoldReason: globus_xio: The GSI XIO dri...   \n",
       "5   Condor HoldReason: CREAM error: Job has been t...   \n",
       "23            LRMS error: (-1) Job missing from SLURM   \n",
       "11  Condor HoldReason: None ; Condor RemoveReason:...   \n",
       "25  LRMS error: (-1) RemoveReason: Job removed by ...   \n",
       "28                                      Unknown error   \n",
       "7   Condor HoldReason: CREAM error: Transfer faile...   \n",
       "\n",
       "                                              indices  cluster_size  \n",
       "4   [1163, 1661, 1948, 1950, 1951, 1952, 1953, 272...          1199  \n",
       "10  [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1...           951  \n",
       "30  [1, 2, 3, 4, 92, 93, 94, 95, 96, 97, 98, 99, 1...           741  \n",
       "0   [71, 72, 73, 76, 184, 185, 187, 189, 190, 192,...           673  \n",
       "12  [0, 22, 114, 115, 116, 117, 118, 126, 127, 128...           667  \n",
       "15  [217, 218, 248, 249, 250, 251, 252, 253, 254, ...           532  \n",
       "29  [64, 65, 66, 123, 124, 133, 134, 135, 136, 137...           308  \n",
       "27  [158, 160, 183, 282, 435, 577, 658, 666, 667, ...           237  \n",
       "6   [741, 283, 284, 292, 685, 1123, 1345, 1648, 20...           112  \n",
       "8   [2371, 5218, 648, 649, 650, 657, 927, 1115, 11...            41  \n",
       "16  [265, 266, 267, 887, 888, 889, 890, 1302, 1966...            40  \n",
       "26  [153, 205, 206, 325, 326, 669, 1664, 1921, 197...            38  \n",
       "3   [1092, 1689, 2365, 2588, 3066, 3067, 3492, 364...            38  \n",
       "2   [2070, 2167, 3503, 4057, 4060, 4956, 5339, 538...            36  \n",
       "13  [383, 698, 738, 1346, 1429, 1561, 1681, 2335, ...            30  \n",
       "14  [437, 704, 1348, 1349, 2072, 2354, 2456, 2653,...            30  \n",
       "24  [789, 952, 2142, 2143, 2297, 2392, 2393, 2394,...            11  \n",
       "22  [1882, 1883, 4833, 4834, 5318, 5319, 5704, 571...            10  \n",
       "9      [154, 155, 1497, 1498, 2831, 3093, 3094, 3095]             8  \n",
       "20                [350, 2283, 4358, 2282, 2711, 2731]             6  \n",
       "19                           [2160, 2251, 3336, 4326]             4  \n",
       "1                                   [120, 1762, 3582]             3  \n",
       "21                                         [129, 915]             2  \n",
       "17                                       [2159, 4700]             2  \n",
       "18                                              [992]             1  \n",
       "5                                              [1662]             1  \n",
       "23                                              [178]             1  \n",
       "11                                             [1733]             1  \n",
       "25                                             [5725]             1  \n",
       "28                                              [795]             1  \n",
       "7                                              [4229]             1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Condor HoldReason: CREAM error: Job has been terminated (got SIGTERM); Cannot upload file:///home/gridpools/atlaspilot0071/home_cream_668136194/CREAM668136194/grid.17552583.8.out into gsiftp://calc2.t1.grid.kiae.ru/var/cream_sandbox/atlaspilot/CN_Robot__AT'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.in_cluster(cluster.result, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print only patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Condor HoldReason:｟*｠:｟*｠ ; Worker canceled by harvester due to held too long or not found',\n",
       "       \"Condor HoldReason: HTCondor-CE held job due to no matching routes, route job limit, or route failure threshold; see 'HTCondor-CE Troubleshooting Guide' ; Worker canceled by harvester due to held too long or not found\",\n",
       "       'Payload execution error: returned non-zero',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: Maximum number of jobs already in queue MSG=total number of jobs in queue exceeds the queue limit: user｟*｠@｟*｠, queue｟*｠',\n",
       "       'Condor HoldReason: None ; Condor RemoveReason: removed by SYSTEM_PERIODIC_REMOVE due to job restarted undesirably.',\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '(x509userproxysubject =?= undefined) | (x509UserProxyExpiration =?= undefined) | (time() > x509UserProxyExpiration) & JobStatus =!= 3 & JobStatus =!= 4) | (RoutedBy =?= null & JobU\",\n",
       "       '｟*｠ not submitted due to incomplete data of the worker',\n",
       "       'LRMS error: (271)｟*｠',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. :｟*｠ failed. 500-globus_xio: Unable to｟*｠ /｟*｠/｟*｠/｟*｠',\n",
       "       'Condor HoldReason: CREAM error: reason=｟*｠',\n",
       "       'Condor HoldReason: submission command failed (exit code = 1) (stdout:) (stderr:sbatch: error: Batch job submission failed: Requested time limit is invalid (missing or exceeds some limit)-Error from sbatch: -) ; Worker canceled by harvester due to held too',\n",
       "       'LRMS error: (1) Job failed',\n",
       "       'Condor HoldReason: CREAM error: Cannot move ISB (retry_copy ${globus_transfer_cmd} gsiftp:/｟*｠/var/cream_sandbox/atlasprd/CN_Robot__ATLAS_Pilot1_CN_614260_CN_atlpilo1_OU_Users_OU_Organic_Units_DC_cern_DC_ch_atlas_Role_production_Capabili',\n",
       "       'Condor HoldReason:｟*｠ error:｟*｠ Error: Received NULL fault; the error is due to another cause: FaultString=[connection error] - FaultCode=[SOAP-ENV:Client] - FaultSubCode=[SOAP-ENV:Client] - FaultDetail=[Connection timed out] ; Worker｟*｠',\n",
       "       'Condor HoldReason:｟*｠ ; Condor RemoveReason: Python-initiated action. (by user atlpan)',\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '( NumJobStarts >= 1 & JobStatus = 1 )' evaluated to TRUE ; Worker canceled by harvester due to held too long or not found\",\n",
       "       'LRMS error: (-1) Job was killed by Condor',\n",
       "       'Job submission to LRMS failed',\n",
       "       'Condor HoldReason: Failed to get expiration time of proxy: unable to read proxy file ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Failed in data staging: Failed checking source replica root:/fax.mwt2.org:1094/pnfs/uchicago.edu/atlasdatadisk/rucio/mc16_13TeV/｟*｠/｟*｠/DAOD_TOPQ1.17829848.｟*｠: Failed to obtain information about file: Permission denied',\n",
       "       'Error reading user generated output file list',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[jobRegister] ErrorCode=[0] Description=[The CREAM service cannot accept jobs at the moment] FaultCause=[｟*｠]｟*｠=[｟*｠ 12:｟*｠:12]｟*｠',\n",
       "       'Failed in data staging: Failed to prepare source srm:/srm-atlas.cern.ch:8443/srm/managerv2?SFN=/castor/cern.ch/grid/atlas/atlasdatatape/ddo/DBRelease/v310701/ddo.000001.Atlas.Ideal.DBRelease.v310701/DBRelease-31.7.1.tar.gz: Failed to prepare source: No su',\n",
       "       'Condor HoldReason: Unspecified gridmanager error',\n",
       "       'Condor HoldReason: globus_xio: The GSI XIO driver failed to establish a secure connection. The failure occured during a handshake read. globus_xio: Operation was canceled globus_xio: Operation timed out ; Worker canceled by harvester due to held too long',\n",
       "       'Condor HoldReason: CREAM error: Job has been terminated (got SIGTERM); Cannot upload file:/home/gridpools/atlaspilot0071/home_cream_668136194/CREAM668136194/grid.17552583.8.out into gsiftp:/calc2.t1.grid.kiae.ru/var/cream_sandbox/atlaspilot/CN_Robot__AT',\n",
       "       'LRMS error: (-1) Job missing from SLURM',\n",
       "       \"Condor HoldReason: None ; Condor RemoveReason: The job attribute PeriodicRemove expression '(JobStatus = 2 & (CurrentTime - EnteredCurrentStatus) > 604800)' evaluated to TRUE\",\n",
       "       'LRMS error: (-1) RemoveReason: Job removed by SYSTEM_PERIODIC_REMOVE due to disk usage exceeding 150 GB.',\n",
       "       'Unknown error',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_gridftp_server_file.c:globus_l_gfs_file_send:3315: 500-globus_l_gfs_file_open failed. 500-globus_gridftp_server_file.c'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.result['pattern'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "43",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 43",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-57b999983360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PyCharmProjects/ClusterLogs/clusterlogs/pipeline.py\u001b[0m in \u001b[0;36min_cluster\u001b[0;34m(self, groups, cluster_label)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0min_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'indices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3735\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3736\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3737\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 43"
     ]
    }
   ],
   "source": [
    "cluster.in_cluster(cluster.result, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split clusters to big (cluster_size >= 1000) and small (cluster_size < 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big, small = cluster.split_clusters(cluster.result, 'cluster_size', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all messages from cluster #40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.in_cluster(clusters, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the performance of all stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
