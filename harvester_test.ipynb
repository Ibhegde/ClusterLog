{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterlogs Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from clusterlogs import pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data from file and create pandas DataFrame with index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('samples/harvester_errors24.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/maria/cernbox/LogsClusterization/Harvester/data_sample.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5726, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CERN_central_A|118722113</td>\n",
       "      <td>Condor HoldReason: None ; Condor RemoveReason:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CERN_central_B|133202736</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>CERN_central_B|133202747</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>CERN_central_B|133201846</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CERN_central_B|133201823</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        id  \\\n",
       "0           0  CERN_central_A|118722113   \n",
       "1           1  CERN_central_B|133202736   \n",
       "2           2  CERN_central_B|133202747   \n",
       "3           3  CERN_central_B|133201846   \n",
       "4           4  CERN_central_B|133201823   \n",
       "\n",
       "                                             message  \n",
       "0  Condor HoldReason: None ; Condor RemoveReason:...  \n",
       "1         Payload execution error: returned non-zero  \n",
       "2         Payload execution error: returned non-zero  \n",
       "3         Payload execution error: returned non-zero  \n",
       "4         Payload execution error: returned non-zero  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'message'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(df['message'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Execute clusterization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pipeline.Chain(df, target, mode='process', model_name='harvester_test.model', matching_accuracy=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size of vocabulary: 610\n",
      "Size of vocabulary after removing tokens that appears only once: 223\n",
      "Size of vocabulary after removing rare tokens: 174\n",
      "Tokenization finished\n",
      "Found 51 equal groups\n",
      "Matching Clusterization!\n",
      "Postprocessed with 39 clusters\n"
     ]
    }
   ],
   "source": [
    "cluster.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Condor HoldReason: CREAM_Delegate Error: Received NULL fault; the error is due to another cause: FaultString=[connection error] - FaultCode=[SOAP-ENV:Client] - FaultSubCode=[SOAP-ENV:Client] - FaultDetail=[Connection timed out] ; Worker canceled by harves',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: Maximum number of jobs already in queue MSG=total number of jobs in queue exceeds the queue limit: user atlasp@lapp-ce01.in2p3.fr, queue atlasMC8-',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: Maximum number of jobs already in queue MSG=total number of jobs in queue exceeds the queue limit: user atlasp@lapp-ce03.in2p3.fr, queue atlasMC8-',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: submit error (Maximum number of jobs already in queue MSG=total number of jobs in queue exceeds the queue limit: user atlasprodusr01@localhost, qu',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[jobRegister] ErrorCode=[0] Description=[The CREAM service cannot accept jobs at the moment] FaultCause=[Threshold for Disk Usage: 95% => Detected value for Partition / : 95%\\\\n\\\\n] Timesta',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[jobRegister] ErrorCode=[0] Description=[The CREAM service cannot accept jobs at the moment] FaultCause=[Submissions are disabled!] Timestamp=[Sat 22 Feb 2020 12:50:12] ; Worker canceled',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: Received NULL fault; the error is due to another cause: FaultString=[connection error] - FaultCode=[SOAP-ENV:Client] - FaultSubCode=[SOAP-ENV:Client] - FaultDetail=[Connection timed out] ; Worker c',\n",
       "       'Condor HoldReason: CREAM error: Job has been terminated (got SIGTERM); Cannot upload file:/home/gridpools/atlaspilot0071/home_cream_668136194/CREAM668136194/grid.17552583.8.out into gsiftp:/calc2.t1.grid.kiae.ru/var/cream_sandbox/atlaspilot/CN_Robot__AT',\n",
       "       'Condor HoldReason: CREAM error: Cannot move ISB (retry_copy ${globus_transfer_cmd} gsiftp:/calc3.t1.grid.kiae.ru/var/cream_sandbox/atlasprd/CN_Robot__ATLAS_Pilot1_CN_614260_CN_atlpilo1_OU_Users_OU_Organic_Units_DC_cern_DC_ch_atlas_Role_production_Capabili',\n",
       "       'Condor HoldReason: CREAM error: Cannot move ISB (retry_copy ${globus_transfer_cmd} gsiftp:/calc2.t1.grid.kiae.ru/var/cream_sandbox/atlasprd/CN_Robot__ATLAS_Pilot1_CN_614260_CN_atlpilo1_OU_Users_OU_Organic_Units_DC_cern_DC_ch_atlas_Role_production_Capabili',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_gridftp_server_file.c:globus_l_gfs_file_send:3315: 500-globus_l_gfs_file_open failed. 500-globus_gridftp_server_file.c',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : callback failed. 500-globus_xio: Unable to connect to 188.185.66.87:31269 500-globus_xio: System error in connect: Connection',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /sandboxes/atlas/CN_Robot__ATLAS_Pilot1_CN_614260_CN_atlpil',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /var/cream_sandbox/pilatlas/CN_Robot__ATLAS_Pilot1_CN_61426',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /var/cream_sandbox/atlasprd/CN_Robot__ATLAS_Pilot1_CN_61426',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /var/cream_sandbox/prdatlas/CN_Robot__ATLAS_Pilot1_CN_61426',\n",
       "       'Condor HoldReason: CREAM error:｟*｠ ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: reason=-10',\n",
       "       'Condor HoldReason: CREAM error: reason=0',\n",
       "       'Condor HoldReason: CREAM error: reason=｟*｠ ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: reason=126; /var/lib/torque/mom_priv/jobs/446406.ce.physics.science.az.SC: ./CREAM362102614_jobWrapper.sh: /bin/sh: bad interpreter: Text file busy ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: Error parsing classad or job not found ; Worker canceled by harvester due to held too long or not found',\n",
       "       \"Condor HoldReason: None ; Condor RemoveReason: The job attribute PeriodicRemove expression '(JobStatus = 2 & (CurrentTime - EnteredCurrentStatus) > 604800)' evaluated to TRUE\",\n",
       "       'Condor HoldReason: None ; Condor RemoveReason: removed by SYSTEM_PERIODIC_REMOVE due to job restarted undesirably.',\n",
       "       'Condor HoldReason: None ; Condor RemoveReason: Python-initiated action. (by user atlpan)',\n",
       "       'Condor HoldReason: NORDUGRID_SUBMIT timed out ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: submission command failed (exit code = 1) (stdout:) (stderr:sbatch: error: Batch job submission failed: Requested time limit is invalid (missing or exceeds some limit)-Error from sbatch: -) ; Worker canceled by harvester due to held too',\n",
       "       'Condor HoldReason: Unspecified gridmanager error',\n",
       "       'Condor HoldReason: Unspecified gridmanager error ; Condor RemoveReason: Python-initiated action. (by user atlpan)',\n",
       "       'Condor HoldReason: Unspecified gridmanager error ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: globus_xio: The GSI XIO driver failed to establish a secure connection. The failure occured during a handshake read. globus_xio: Operation was canceled globus_xio: Operation timed out ; Worker canceled by harvester due to held too long',\n",
       "       'Condor HoldReason: Job not found ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: Failed to get expiration time of proxy: unable to read proxy file ; Worker canceled by harvester due to held too long or not found',\n",
       "       \"Condor HoldReason: HTCondor-CE held job due to no matching routes, route job limit, or route failure threshold; see 'HTCondor-CE Troubleshooting Guide' ; Worker canceled by harvester due to held too long or not found\",\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '( NumJobStarts >= 1 & JobStatus = 1 )' evaluated to TRUE ; Worker canceled by harvester due to held too long or not found\",\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '(x509userproxysubject =?= undefined) | (x509UserProxyExpiration =?= undefined) | (time() > x509UserProxyExpiration) & JobStatus =!= 3 & JobStatus =!= 4) | (RoutedBy =?= null & JobU\",\n",
       "       'Error reading user generated output file list',\n",
       "       'Job submission to LRMS failed', 'LRMS error: (1) Job failed',\n",
       "       'LRMS error: (-1) Job was killed by Condor',\n",
       "       'LRMS error: (-1) Job missing from SLURM',\n",
       "       'LRMS error: (271) Job｟*｠', 'LRMS error: (271) job killed:｟*｠',\n",
       "       'LRMS error: (271) job killed: wall',\n",
       "       'Payload execution error: returned non-zero', 'Unknown error',\n",
       "       'LRMS error: (-1) RemoveReason: Job removed by SYSTEM_PERIODIC_REMOVE due to disk usage exceeding 150 GB.',\n",
       "       'Failed in data staging: Failed checking source replica root:/fax.mwt2.org:1094/pnfs/uchicago.edu/atlasdatadisk/rucio/mc16_13TeV/｟*｠/｟*｠/DAOD_TOPQ1.17829848.｟*｠: Failed to obtain information about file: Permission denied',\n",
       "       'Failed in data staging: Failed checking source replica root:/fax.mwt2.org:1094/pnfs/uchicago.edu/atlasdatadisk/rucio/mc16_13TeV/｟*｠/｟*｠/DAOD_TOPQ1.17829848.｟*｠: Failed to obtain information about file: Permission denied; Failed in data stag',\n",
       "       'Failed in data staging: Failed to prepare source srm:/srm-atlas.cern.ch:8443/srm/managerv2?SFN=/castor/cern.ch/grid/atlas/atlasdatatape/ddo/DBRelease/v310701/ddo.000001.Atlas.Ideal.DBRelease.v310701/DBRelease-31.7.1.tar.gz: Failed to prepare source: No su',\n",
       "       '｟*｠ not submitted due to incomplete data of the worker'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.groups['pattern'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Result: all clusters (big clusters and outliers) - sorted by cluster size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>indices</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Condor HoldReason: HTCondor-CE held job due to...</td>\n",
       "      <td>[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1...</td>\n",
       "      <td>951</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, HTCondor-CE, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Condor HoldReason: CREAM error:｟*｠ ; Worker ca...</td>\n",
       "      <td>[1163, 1277, 1494, 1661, 1948, 1950, 1951, 195...</td>\n",
       "      <td>873</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Payload execution error: returned non-zero</td>\n",
       "      <td>[1, 2, 3, 4, 92, 93, 94, 95, 96, 97, 98, 99, 1...</td>\n",
       "      <td>741</td>\n",
       "      <td>[Payload, ▁, execution, ▁, error, :, ▁, return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Condor HoldReason: CREAM error: BLAH error: su...</td>\n",
       "      <td>[71, 72, 73, 76, 184, 185, 187, 189, 190, 192,...</td>\n",
       "      <td>673</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Condor HoldReason: None ; Condor RemoveReason:...</td>\n",
       "      <td>[0, 22, 114, 115, 116, 117, 118, 126, 127, 128...</td>\n",
       "      <td>667</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, None, ▁, ;, ▁, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Condor HoldReason: The system macro SYSTEM_PER...</td>\n",
       "      <td>[217, 218, 248, 249, 250, 251, 252, 253, 254, ...</td>\n",
       "      <td>532</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, The, ▁, system, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>｟*｠ not submitted due to incomplete data of th...</td>\n",
       "      <td>[64, 65, 66, 123, 124, 133, 134, 135, 136, 137...</td>\n",
       "      <td>308</td>\n",
       "      <td>[｟*｠, ▁, not, ▁, submitted, ▁, due, ▁, to, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Condor HoldReason:｟*｠ ; Worker canceled by har...</td>\n",
       "      <td>[58, 59, 60, 61, 62, 63, 122, 230, 368, 369, 3...</td>\n",
       "      <td>183</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, ｟*｠, ▁, ｟*｠, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>LRMS error: (271) job killed:｟*｠</td>\n",
       "      <td>[446, 1098, 1135, 1493, 1705, 1729, 2146, 2486...</td>\n",
       "      <td>159</td>\n",
       "      <td>[LRMS, ▁, error, :, ▁, (, 271, ), ▁, job, ▁, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Condor HoldReason: Unspecified gridmanager err...</td>\n",
       "      <td>[5, 119, 131, 132, 222, 223, 226, 227, 279, 28...</td>\n",
       "      <td>132</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, Unspecified, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Condor HoldReason: CREAM error: Transfer faile...</td>\n",
       "      <td>[741, 1230, 1949, 4829, 5346, 5516, 283, 284, ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>LRMS error: (271) Job｟*｠</td>\n",
       "      <td>[158, 160, 183, 282, 435, 577, 658, 666, 667, ...</td>\n",
       "      <td>78</td>\n",
       "      <td>[LRMS, ▁, error, :, ▁, (, 271, ), ▁, Job, ▁, ｟*｠]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Condor HoldReason: CREAM error: reason=｟*｠</td>\n",
       "      <td>[2371, 5218, 648, 649, 650, 657, 927, 1115, 11...</td>\n",
       "      <td>41</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Condor HoldReason: submission command failed (...</td>\n",
       "      <td>[265, 266, 267, 887, 888, 889, 890, 1302, 1966...</td>\n",
       "      <td>40</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, submission, ▁, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>LRMS error: (1) Job failed</td>\n",
       "      <td>[153, 205, 206, 325, 326, 669, 1664, 1921, 197...</td>\n",
       "      <td>38</td>\n",
       "      <td>[LRMS, ▁, error, :, ▁, (, 1, ), ▁, Job, ▁, fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Condor HoldReason: CREAM error: Cannot move IS...</td>\n",
       "      <td>[1344, 1947, 2021, 2745, 2746, 2811, 3647, 364...</td>\n",
       "      <td>38</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Condor HoldReason:｟*｠ Error: Received NULL fau...</td>\n",
       "      <td>[816, 817, 818, 1238, 1239, 1240, 2163, 2164, ...</td>\n",
       "      <td>36</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, ｟*｠, ▁, Error, :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Condor HoldReason: The system macro SYSTEM_PER...</td>\n",
       "      <td>[437, 704, 1348, 1349, 2072, 2354, 2456, 2653,...</td>\n",
       "      <td>30</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, The, ▁, system, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Condor HoldReason: None ; Condor RemoveReason:...</td>\n",
       "      <td>[383, 698, 738, 1346, 1429, 1561, 1681, 2335, ...</td>\n",
       "      <td>27</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, None, ▁, ;, ▁, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>LRMS error: (-1) Job was killed by Condor</td>\n",
       "      <td>[789, 952, 2142, 2143, 2297, 2392, 2393, 2394,...</td>\n",
       "      <td>11</td>\n",
       "      <td>[LRMS, ▁, error, :, ▁, (, -, 1, ), ▁, Job, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Condor HoldReason: Error parsing classad or jo...</td>\n",
       "      <td>[150, 151, 202, 939, 1078, 2710, 2712, 2713, 2...</td>\n",
       "      <td>10</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, Error, ▁, parsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Job submission to LRMS failed</td>\n",
       "      <td>[1882, 1883, 4833, 4834, 5318, 5319, 5704, 571...</td>\n",
       "      <td>10</td>\n",
       "      <td>[Job, ▁, submission, ▁, to, ▁, LRMS, ▁, failed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Condor HoldReason: Failed to get expiration ti...</td>\n",
       "      <td>[154, 155, 1497, 1498, 2831, 3093, 3094, 3095]</td>\n",
       "      <td>8</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, Failed, ▁, to, ▁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Failed in data staging: Failed checking source...</td>\n",
       "      <td>[350, 2283, 4358, 2282, 2711, 2731]</td>\n",
       "      <td>6</td>\n",
       "      <td>[Failed, ▁, in, ▁, data, ▁, staging, :, ▁, Fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Error reading user generated output file list</td>\n",
       "      <td>[2160, 2251, 3336, 4326]</td>\n",
       "      <td>4</td>\n",
       "      <td>[Error, ▁, reading, ▁, user, ▁, generated, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Condor HoldReason: Unspecified gridmanager err...</td>\n",
       "      <td>[608, 2390, 3092]</td>\n",
       "      <td>3</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, Unspecified, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Condor HoldReason: CREAM error: CREAM_Job_Regi...</td>\n",
       "      <td>[1762, 3582]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Failed in data staging: Failed to prepare sour...</td>\n",
       "      <td>[129, 915]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Failed, ▁, in, ▁, data, ▁, staging, :, ▁, Fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Condor HoldReason: Unspecified gridmanager error</td>\n",
       "      <td>[2159, 4700]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, Unspecified, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Condor HoldReason: CREAM error: reason=126; /v...</td>\n",
       "      <td>[1207]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Condor HoldReason: None ; Condor RemoveReason:...</td>\n",
       "      <td>[1733]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, None, ▁, ;, ▁, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Condor HoldReason: CREAM error: Transfer faile...</td>\n",
       "      <td>[4229]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Condor HoldReason: CREAM error: CREAM_Job_Regi...</td>\n",
       "      <td>[120]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Condor HoldReason: CREAM error: Transfer faile...</td>\n",
       "      <td>[4000]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Condor HoldReason: CREAM error: Job has been t...</td>\n",
       "      <td>[1662]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Unknown error</td>\n",
       "      <td>[795]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Unknown, ▁, error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Condor HoldReason: globus_xio: The GSI XIO dri...</td>\n",
       "      <td>[992]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Condor, ▁, HoldReason, :, ▁, globus_xio, :, ▁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>LRMS error: (-1) Job missing from SLURM</td>\n",
       "      <td>[178]</td>\n",
       "      <td>1</td>\n",
       "      <td>[LRMS, ▁, error, :, ▁, (, -, 1, ), ▁, Job, ▁, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LRMS error: (-1) RemoveReason: Job removed by ...</td>\n",
       "      <td>[5725]</td>\n",
       "      <td>1</td>\n",
       "      <td>[LRMS, ▁, error, :, ▁, (, -, 1, ), ▁, RemoveRe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pattern  \\\n",
       "11  Condor HoldReason: HTCondor-CE held job due to...   \n",
       "28  Condor HoldReason: CREAM error:｟*｠ ; Worker ca...   \n",
       "21         Payload execution error: returned non-zero   \n",
       "35  Condor HoldReason: CREAM error: BLAH error: su...   \n",
       "2   Condor HoldReason: None ; Condor RemoveReason:...   \n",
       "13  Condor HoldReason: The system macro SYSTEM_PER...   \n",
       "38  ｟*｠ not submitted due to incomplete data of th...   \n",
       "4   Condor HoldReason:｟*｠ ; Worker canceled by har...   \n",
       "20                   LRMS error: (271) job killed:｟*｠   \n",
       "8   Condor HoldReason: Unspecified gridmanager err...   \n",
       "27  Condor HoldReason: CREAM error: Transfer faile...   \n",
       "19                           LRMS error: (271) Job｟*｠   \n",
       "29         Condor HoldReason: CREAM error: reason=｟*｠   \n",
       "5   Condor HoldReason: submission command failed (...   \n",
       "16                         LRMS error: (1) Job failed   \n",
       "24  Condor HoldReason: CREAM error: Cannot move IS...   \n",
       "31  Condor HoldReason:｟*｠ Error: Received NULL fau...   \n",
       "12  Condor HoldReason: The system macro SYSTEM_PER...   \n",
       "3   Condor HoldReason: None ; Condor RemoveReason:...   \n",
       "17          LRMS error: (-1) Job was killed by Condor   \n",
       "32  Condor HoldReason: Error parsing classad or jo...   \n",
       "15                      Job submission to LRMS failed   \n",
       "10  Condor HoldReason: Failed to get expiration ti...   \n",
       "1   Failed in data staging: Failed checking source...   \n",
       "14      Error reading user generated output file list   \n",
       "7   Condor HoldReason: Unspecified gridmanager err...   \n",
       "36  Condor HoldReason: CREAM error: CREAM_Job_Regi...   \n",
       "34  Failed in data staging: Failed to prepare sour...   \n",
       "6    Condor HoldReason: Unspecified gridmanager error   \n",
       "37  Condor HoldReason: CREAM error: reason=126; /v...   \n",
       "33  Condor HoldReason: None ; Condor RemoveReason:...   \n",
       "25  Condor HoldReason: CREAM error: Transfer faile...   \n",
       "30  Condor HoldReason: CREAM error: CREAM_Job_Regi...   \n",
       "26  Condor HoldReason: CREAM error: Transfer faile...   \n",
       "23  Condor HoldReason: CREAM error: Job has been t...   \n",
       "22                                      Unknown error   \n",
       "9   Condor HoldReason: globus_xio: The GSI XIO dri...   \n",
       "18            LRMS error: (-1) Job missing from SLURM   \n",
       "0   LRMS error: (-1) RemoveReason: Job removed by ...   \n",
       "\n",
       "                                              indices  cluster_size  \\\n",
       "11  [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1...           951   \n",
       "28  [1163, 1277, 1494, 1661, 1948, 1950, 1951, 195...           873   \n",
       "21  [1, 2, 3, 4, 92, 93, 94, 95, 96, 97, 98, 99, 1...           741   \n",
       "35  [71, 72, 73, 76, 184, 185, 187, 189, 190, 192,...           673   \n",
       "2   [0, 22, 114, 115, 116, 117, 118, 126, 127, 128...           667   \n",
       "13  [217, 218, 248, 249, 250, 251, 252, 253, 254, ...           532   \n",
       "38  [64, 65, 66, 123, 124, 133, 134, 135, 136, 137...           308   \n",
       "4   [58, 59, 60, 61, 62, 63, 122, 230, 368, 369, 3...           183   \n",
       "20  [446, 1098, 1135, 1493, 1705, 1729, 2146, 2486...           159   \n",
       "8   [5, 119, 131, 132, 222, 223, 226, 227, 279, 28...           132   \n",
       "27  [741, 1230, 1949, 4829, 5346, 5516, 283, 284, ...           111   \n",
       "19  [158, 160, 183, 282, 435, 577, 658, 666, 667, ...            78   \n",
       "29  [2371, 5218, 648, 649, 650, 657, 927, 1115, 11...            41   \n",
       "5   [265, 266, 267, 887, 888, 889, 890, 1302, 1966...            40   \n",
       "16  [153, 205, 206, 325, 326, 669, 1664, 1921, 197...            38   \n",
       "24  [1344, 1947, 2021, 2745, 2746, 2811, 3647, 364...            38   \n",
       "31  [816, 817, 818, 1238, 1239, 1240, 2163, 2164, ...            36   \n",
       "12  [437, 704, 1348, 1349, 2072, 2354, 2456, 2653,...            30   \n",
       "3   [383, 698, 738, 1346, 1429, 1561, 1681, 2335, ...            27   \n",
       "17  [789, 952, 2142, 2143, 2297, 2392, 2393, 2394,...            11   \n",
       "32  [150, 151, 202, 939, 1078, 2710, 2712, 2713, 2...            10   \n",
       "15  [1882, 1883, 4833, 4834, 5318, 5319, 5704, 571...            10   \n",
       "10     [154, 155, 1497, 1498, 2831, 3093, 3094, 3095]             8   \n",
       "1                 [350, 2283, 4358, 2282, 2711, 2731]             6   \n",
       "14                           [2160, 2251, 3336, 4326]             4   \n",
       "7                                   [608, 2390, 3092]             3   \n",
       "36                                       [1762, 3582]             2   \n",
       "34                                         [129, 915]             2   \n",
       "6                                        [2159, 4700]             2   \n",
       "37                                             [1207]             1   \n",
       "33                                             [1733]             1   \n",
       "25                                             [4229]             1   \n",
       "30                                              [120]             1   \n",
       "26                                             [4000]             1   \n",
       "23                                             [1662]             1   \n",
       "22                                              [795]             1   \n",
       "9                                               [992]             1   \n",
       "18                                              [178]             1   \n",
       "0                                              [5725]             1   \n",
       "\n",
       "                                             sequence  \n",
       "11  [Condor, ▁, HoldReason, :, ▁, HTCondor-CE, ▁, ...  \n",
       "28  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "21  [Payload, ▁, execution, ▁, error, :, ▁, return...  \n",
       "35  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "2   [Condor, ▁, HoldReason, :, ▁, None, ▁, ;, ▁, C...  \n",
       "13  [Condor, ▁, HoldReason, :, ▁, The, ▁, system, ...  \n",
       "38  [｟*｠, ▁, not, ▁, submitted, ▁, due, ▁, to, ▁, ...  \n",
       "4   [Condor, ▁, HoldReason, :, ▁, ｟*｠, ▁, ｟*｠, ▁, ...  \n",
       "20  [LRMS, ▁, error, :, ▁, (, 271, ), ▁, job, ▁, k...  \n",
       "8   [Condor, ▁, HoldReason, :, ▁, Unspecified, ▁, ...  \n",
       "27  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "19  [LRMS, ▁, error, :, ▁, (, 271, ), ▁, Job, ▁, ｟*｠]  \n",
       "29  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "5   [Condor, ▁, HoldReason, :, ▁, submission, ▁, c...  \n",
       "16  [LRMS, ▁, error, :, ▁, (, 1, ), ▁, Job, ▁, fai...  \n",
       "24  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "31  [Condor, ▁, HoldReason, :, ▁, ｟*｠, ▁, Error, :...  \n",
       "12  [Condor, ▁, HoldReason, :, ▁, The, ▁, system, ...  \n",
       "3   [Condor, ▁, HoldReason, :, ▁, None, ▁, ;, ▁, C...  \n",
       "17  [LRMS, ▁, error, :, ▁, (, -, 1, ), ▁, Job, ▁, ...  \n",
       "32  [Condor, ▁, HoldReason, :, ▁, Error, ▁, parsin...  \n",
       "15    [Job, ▁, submission, ▁, to, ▁, LRMS, ▁, failed]  \n",
       "10  [Condor, ▁, HoldReason, :, ▁, Failed, ▁, to, ▁...  \n",
       "1   [Failed, ▁, in, ▁, data, ▁, staging, :, ▁, Fai...  \n",
       "14  [Error, ▁, reading, ▁, user, ▁, generated, ▁, ...  \n",
       "7   [Condor, ▁, HoldReason, :, ▁, Unspecified, ▁, ...  \n",
       "36  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "34  [Failed, ▁, in, ▁, data, ▁, staging, :, ▁, Fai...  \n",
       "6   [Condor, ▁, HoldReason, :, ▁, Unspecified, ▁, ...  \n",
       "37  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "33  [Condor, ▁, HoldReason, :, ▁, None, ▁, ;, ▁, C...  \n",
       "25  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "30  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "26  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "23  [Condor, ▁, HoldReason, :, ▁, CREAM, ▁, error,...  \n",
       "22                                [Unknown, ▁, error]  \n",
       "9   [Condor, ▁, HoldReason, :, ▁, globus_xio, :, ▁...  \n",
       "18  [LRMS, ▁, error, :, ▁, (, -, 1, ), ▁, Job, ▁, ...  \n",
       "0   [LRMS, ▁, error, :, ▁, (, -, 1, ), ▁, RemoveRe...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Failed in data staging: Failed to prepare destination srm://srm.ndgf.org:8443/srm/managerv2?SFN=/atlas/disk/atlasdatadisk/rucio/mc16_13TeV/e8/e9/AOD.19967297._000199.pool.root.1:checksumtype=adler32:checksumvalue=2b028a5e: Failed to prepare destination: Fi'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.in_cluster(cluster.result, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print only patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Payload execution error: returned non-zero',\n",
       "       'JOB id=｟*｠ not found',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: Maximum number of jobs already in queue MSG=total number of jobs in queue exceeds the queue limit: user｟*｠@｟*｠ queue｟*｠',\n",
       "       'submission failed: Exception OSError: [Errno 28] No space left on device',\n",
       "       \"Condor HoldReason: HTCondor-CE held job due to no matching routes, route job limit, or route failure threshold; see 'HTCondor-CE Troubleshooting Guide'\",\n",
       "       'LRMS error: (271) job killed:｟*｠',\n",
       "       'LRMS error: (-1) Job finished with unknown exit code',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_l_gfs_file_open failed. 500-globus_xio: Unable to open file /｟*｠/cream_sandbox/｟*｠/｟*｠',\n",
       "       '｟*｠ not submitted due to incomplete data of the worker',\n",
       "       'Condor HoldReason:｟*｠ to｟*｠ ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Failed in data staging: Failed to prepare source srm:/srm.ndgf.org:8443/srm/managerv2?SFN=/atlas/disk/atlasdatadisk/rucio/｟*｠/｟*｠/｟*｠/｟*｠.｟*｠: Failed to prepare source: Resource temporarily unavailable: File｟*｠',\n",
       "       'Condor HoldReason: CREAM error:｟*｠ ; Worker canceled by harvester due to held too long or not found',\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '(x509userproxysubject =?= undefined) | (x509UserProxyExpiration =?= undefined) | (time() > x509UserProxyExpiration) & JobStatus =!= 3 & JobStatus =!= 4) | (RoutedBy =?= null & JobU\",\n",
       "       'LRMS error: (-1) Job missing from SLURM',\n",
       "       'Condor HoldReason:｟*｠:｟*｠ ; Worker canceled by harvester due to held too long or not found',\n",
       "       'LRMS error: (｟*｠) Job｟*｠',\n",
       "       'Condor HoldReason: CREAM error: Cannot move ISB (retry_copy ${globus_transfer_cmd} gsiftp:/｟*｠/var/cream_sandbox/｟*｠/｟*｠',\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '( NumJobStarts >= 1 & JobStatus = 1 )' evaluated to TRUE ; Worker canceled by harvester due to held too long or not found\",\n",
       "       'Condor HoldReason:｟*｠ Error: Received NULL fault; the error is due to another cause: FaultString=[connection error] - FaultCode=[SOAP-ENV:Client] - FaultSubCode=[SOAP-ENV:Client] - FaultDetail=[｟*｠]',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[jobRegister] ErrorCode=[0] Description=[The CREAM service cannot accept jobs at the moment] FaultCause=[Submissions are disabled!] Timestamp=[｟*｠ Dec 2019｟*｠:｟*｠:｟*｠] ; Worker canceled',\n",
       "       'Condor HoldReason:｟*｠ Error: Connection to service [https:/creamce3.goegrid.gwdg.de:8443/ce-cream/services/｟*｠] failed: FaultString=[SSL error] - FaultCode=[SOAP-ENV:Client] - FaultSubCode=[SOAP-ENV:Client] - FaultDetail=[SSL｟*｠',\n",
       "       'Failed in data staging: Failed to prepare source srm:/srm-atlas.cern.ch:8443/srm/managerv2?SFN=/castor/cern.ch/grid/atlas/rucio/derived/｟*｠/｟*｠/｟*｠/｟*｠/｟*｠',\n",
       "       'Condor HoldReason: CREAM_Delegate Error: Received NULL fault; the error is due to another cause: FaultString=[The service cannot be found for the endpoint reference (EPR) https:/clrccece01.in2p3.fr:8443/ce-cream/services/gridsite-delegation] - FaultCode=[',\n",
       "       'LRMS error: (｟*｠) Job failed',\n",
       "       'LRMS error: (-1) RemoveReason: Job removed by SYSTEM_PERIODIC_REMOVE due to｟*｠.',\n",
       "       'LRMS error: (1) Job failed with exit code 1',\n",
       "       'Condor HoldReason: Error receiving files from schedd osgserv06.slac.stanford.edu: DCSchedd:receiveJobSandbox:7003:File transfer failed for target job｟*｠: SCHEDD at 134.79.198.164 failed to send file(s) to <｟*｠:｟*｠>: error reading from /',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_xio: Unable to connect to｟*｠:2811 globus_xio: System error in connect: Connection timed out globus_xio: A system call failed: Connection timed out ; Worker canceled by｟*｠',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: Bad UID for job execution MSG=could not authorize user atlasp from｟*｠) N/A (jobId =｟*｠) ; Worker canceled by harvest',\n",
       "       'Failed in data staging: Failed to prepare source srm:/srm.triumf.ca:8443/srm/managerv2?SFN=/atlas/tape/｟*｠/｟*｠/AOD/｟*｠/｟*｠/｟*｠',\n",
       "       \"Failed to create a JOB; HTTPSConnectionPool(host='127.0.0.1', port=6443): Max retries exceeded with url: /apis/batch/v1/namespaces/default/jobs (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at｟*｠>: Failed to establish a new connection: [Errno 111] Connection refused',)\",\n",
       "       'LRMS error: (-1) ExitReason: died on signal 1 (Hangup)',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[jobRegister] ErrorCode=[0] Description=[The CREAM service cannot accept jobs at the moment] FaultCause=[Threshold for FTP Connection: 30 => Detected value for FTP Connection: 30\\\\n\\\\n] Tim',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:qsub: Invalid｟*｠=｟*｠ not｟*｠) N/A (jobId =｟*｠) ; Worker canceled by harvester due to held too long or not found',\n",
       "       'LRMS error: (｟*｠) Job missing from SLURM, exitcode recovered from session directory',\n",
       "       'Failed in data staging: Could not resolve any source replicas for rucio:/rucio-lb-prod.cern.ch/replicas/｟*｠/｟*｠.｟*｠.｟*｠: Resolving of index service for source failed: Failed｟*｠',\n",
       "       'Condor HoldReason: Unspecified gridmanager error',\n",
       "       'Error reading user generated output file list',\n",
       "       '｟*｠+ long usatlas 512｟*｠:0', 'LRMS error: (｟*｠) Node fail',\n",
       "       'Condor HoldReason: CREAM error: reason=127; /｟*｠/｟*｠: line｟*｠: ./｟*｠: No such file or directory ; Worker canceled by harvester due to held too long or not found',\n",
       "       '｟*｠+ regular m2616 6800 PENDING 0:0',\n",
       "       'Failed in data staging: Failed checking source replica root:/｟*｠:1094/dpm/｟*｠/home/atlas/atlasdatadisk/rucio/｟*｠/｟*｠/｟*｠/｟*｠.｟*｠: Failed to obtain information about file:｟*｠',\n",
       "       'Failed in data staging: Failed to prepare source srm:/srm.ndgf.org:8443/srm/managerv2?SFN=/atlas/disk/atlasdatadisk/rucio/data16_hip8TeV/｟*｠/｟*｠/｟*｠.｟*｠.｟*｠: Failed to prepare source: Resource te',\n",
       "       'Condor HoldReason: Error locating schedd htc01.ppgrid1.rhul.ac.uk',\n",
       "       'Condor HoldReason: CREAM error: reason=｟*｠',\n",
       "       'Condor HoldReason: CREAM error: Job has been terminated (got SIGXCPU);｟*｠',\n",
       "       'Failed in data staging: Failed checking source replica root:/xrootd-at1-door.pic.es:1094/pnfs/pic.es/data/atlas/atlasdatadisk/rucio/data17_13TeV/｟*｠/｟*｠/AOD.13673527.｟*｠: Failed to obtain information about file: Permission denied',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 530 530-Login incorrect. : globus_gss_assist: Error invoking callout 530-globus_callout_module: The callout returned an error 530-an unknown error occu',\n",
       "       'submission failed:',\n",
       "       'LRMS error: (-1) Job missing from SLURM|Failed in data staging: Failed to prepare destination srm:/｟*｠:8443/srm/managerv2?SFN=/｟*｠/｟*｠/｟*｠/atlas/atlasdatadisk/rucio/mc16_13TeV/｟*｠/｟*｠/｟*｠.｟*｠:checksumtype=｟*｠',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[jobRegister] Timestamp=[｟*｠ Dec 2019｟*｠:｟*｠:｟*｠] ErrorCode=[0] Description=[system error] FaultCause=[database error occurred] ; Worker canceled by harvester due to held too long or no',\n",
       "       'Condor HoldReason:｟*｠ error:｟*｠ failed: globus_xio: System error in｟*｠: Connection reset by peer globus_xio: A system call failed: Connection reset by peer ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Failed in data staging: Failed checking source replica root:/xrootd-at1-door.pic.es:1094/pnfs/pic.es/data/atlas/tape/atlasmctape/mc16_13TeV/HITS/e7791_e7400_a875/mc16_13TeV.411327.PhPy8EG_A14_ttbar_hdamp258p75_SSdRon_dil.simul.HITS.e7791_e7400_a875_tid1',\n",
       "       'Condor HoldReason: CREAM error:｟*｠ Error: MethodName=[｟*｠] ErrorCode=[0] Description=[Authorization failure: No PEP Server [https:/｟*｠:8154/authz] was able to process the request] FaultCause=[Authorization error]',\n",
       "       'Job submission to LRMS failed',\n",
       "       \"Condor HoldReason: The system macro SYSTEM_PERIODIC_HOLD expression '( NumJobStarts >= 1 & JobStatus = 1 )' evaluated to TRUE\",\n",
       "       'condor job submissionHost=LOCAL batchID=｟*｠ not found. Skipped',\n",
       "       \"LRMS error: (-1) RemoveReason: The system macro SYSTEM_PERIODIC_REMOVE expression '( RemoteWallClockTime > 168 * 60 * 60 ) | ( RemoteSysCpu + RemoteUserCpu > 336 * 60 * 60 ) | ( ( JobStatus = 5 & ( CurrentTime - EnteredCurrentStatus ) > 30 * 60 ) ) |\",\n",
       "       'Failed in data staging: Failed checking source replica root:/｟*｠:1094/｟*｠/｟*｠/｟*｠/atlas/atlasdatadisk/rucio/｟*｠/｟*｠/｟*｠/｟*｠.｟*｠: Failed to obtain information about file: Permission denied',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 530 Please login with USER and PASS. ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: globus_xio: Unable to connect to｟*｠:2811 globus_xio: System error in connect: Connection timed out globus_xio: A system call failed: Connection timed out ; Worker canceled by harvester due to held too long or｟*｠',\n",
       "       'Failed in data staging: Could not resolve any source replicas for rucio:/rucio-lb-prod.cern.ch/replicas/｟*｠/｟*｠.｟*｠',\n",
       "       'Condor HoldReason: Spooling input data files ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM_Delegate Error: Connection to service [http(s):/clrccece01.in2p3.fr/ce-cream/services/gridsite-delegation] failed: FaultString=[HTTP Error] - FaultCode=[SOAP-ENV:Server] - FaultSubCode=[SOAP-ENV:Server] - FaultDetail=[HTTP/1.1 400',\n",
       "       \"Failed to create a JOB; ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')\",\n",
       "       'Condor HoldReason: Error connecting to schedd htc01.ppgrid1.rhul.ac.uk: SECMAN:2007:Failed to received post-auth ClassAd|AUTHENTICATE:1004:Failed to authenticate using FS ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: Error sending files to schedd｟*｠: DCSchedd:spoolJobFiles:7002:File transfer failed for target job｟*｠: Failed to receive GoAhead message from｟*｠. ; Worker canceled by harvester due to held too long｟*｠',\n",
       "       'Condor HoldReason: Job removed from batch queue manually',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : callback failed. 500-globus_xio: Unable to connect to｟*｠:｟*｠ 500-globus_xio: System error in connect:｟*｠',\n",
       "       'Unknown error',\n",
       "       'Failed in data staging: Failed checking source replica root:/lapp-se01.in2p3.fr:1094/dpm/in2p3.fr/home/atlas/atlasdatadisk/rucio/mc15_13TeV/｟*｠/｟*｠/EVNT.18691015.｟*｠: Failed to obtain information about file: Permission denied｟*｠ Failed in｟*｠',\n",
       "       'Failed in data staging: Failed checking source replica davs:/gridftp-b1-1.mi.infn.it:8443/webdav/atlas/atlaslocalgroupdisk/rucio/mc16_13TeV/｟*｠/｟*｠/AOD.12976014.｟*｠: Failed to obtain information about file: SSL error, \"sslv3 alert handshake',\n",
       "       'Condor HoldReason: CREAM error: Cannot move /home/atlasprd031/home_cr006_920443897/CREAM920443897/./runpilot2-wrapper.sh to /home/atlasprd031/home_cr006_920443897/CREAM920443897; mv: cannot stat /home/atlasprd031/home_cr006_920443897/CREAM920443897/./ru',\n",
       "       'Condor HoldReason: Unspecified gridmanager error ; Condor RemoveReason: Python-initiated action. (by user atlpan)',\n",
       "       'LRMS error: (24) Job exceeded time limit.',\n",
       "       'Failed in data staging: Failed checking source replica https:/atlas.bluegrass.nsc.liu.se:443/arex/cache/rucio:/rucio-lb-prod.cern.ch/replicas/mc16_13TeV/DAOD_SUSY1.18927539._000606.pool.root.1: Failed to obtain information about file: No such file or dir',\n",
       "       'LRMS error: (-1) Job missing from SLURM|Failed in data staging: Failed to prepare destination srm:/srm.ndgf.org:8443/srm/managerv2?SFN=/atlas/disk/atlasdatadisk/rucio/｟*｠/｟*｠/｟*｠/｟*｠.｟*｠:checksumtype=adler32:checksumvalue',\n",
       "       'Condor HoldReason:｟*｠:｟*｠: an end-of-file was reached globus_xio: An end of file occurred ; Worker canceled by harvester due to held too long or not found',\n",
       "       ':｟*｠',\n",
       "       'Failed in data staging: Could not resolve any source replicas for rucio:/rucio-lb-prod.cern.ch/replicas/mc16_13TeV/AOD.19562484.｟*｠; Failed in data staging: Could not resolve any source replicas for rucio:/rucio-lb-prod.cern.ch/replicas/m',\n",
       "       'Failed in data staging: Could not resolve any source replicas for rucio:/rucio-lb-prod.cern.ch/replicas/mc16_13TeV/｟*｠.｟*｠: Resolving of index service for source failed: Failed to contact server: Connection was closed',\n",
       "       'Failed in data staging: Failed checking source replica root:/xrootd.aglt2.org:1094/pnfs/aglt2.org/atlasdatadisk/rucio/data15_13TeV/｟*｠/｟*｠/AOD.11227496.｟*｠: Failed to obtain information about file: Permission denied',\n",
       "       'LRMS error: (15) Job was cancelled by SLURM',\n",
       "       'Failed in data staging: Failed checking source replica root:/xrootd-at1-door.pic.es:1094/pnfs/pic.es/data/atlas/tape/atlasdatatape/data15_13TeV/AOD/r9264_p3083/data15_13TeV.00279279.physics_Main.merge.AOD.r9264_p3083_tid11253249_00/AOD.11253249.｟*｠.',\n",
       "       \"Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:mkdir: cannot create directory `/var/jwgen/crm03_008270025.debug': File exists-cp: accessing `/var/jwgen/crm03_008270025.debug/submit.req': Permission\",\n",
       "       'Condor HoldReason: globus_xio: Unable to connect to t1-arc02.grid.sinica.edu.tw:2811 globus_xio: globus_libc_getaddrinfo failed. globus_common: Name or service not known ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: BLAH error: submission command failed (exit code = 1) (stdout:) (stderr:/usr/libexec/pbs_submit.sh: line 134: [: -gt: unary operator expected-pbs_iff: cannot read reply from pbs_server-No Permission.-qsub: cannot connect to',\n",
       "       'Condor HoldReason: Network error talking to schedd, probably an authorization failure ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: Cannot move /home/pilatlas011/home_cr006_435993649/CREAM435993649/./runpilot2-wrapper.sh to /home/pilatlas011/home_cr006_435993649/CREAM435993649 ; Worker canceled by harvester due to held too long or not found',\n",
       "       'Condor HoldReason: CREAM error: CREAM_Job_Register Error: MethodName=[JobRegister] ErrorCode=[0] Description=[CN=Robot: ATLAS Pilot1,CN=614260,CN=atlpilo1,OU=Users,OU=Organic Units,DC=cern,DC=ch not authorized for {http:/glite.org/2007/11/ce/cream/types}J',\n",
       "       \"Failed in data staging: Failed writing to destination: file:/arc/abisko/qf-cache282/data/86/c1103228405354a9e0ce0d688b76b0a76c3346 : Can't write to destination: File exists: Failed to create file /arc/abisko/qf-cache282/data/86/c1103228405354a9e0ce0d688b76\",\n",
       "       'Failed in data staging: Failed to prepare destination srm:/srm.ndgf.org:8443/srm/managerv2?SFN=/atlas/disk/atlasdatadisk/rucio/mc16_13TeV/e8/e9/AOD.19967297._000199.pool.root.1:checksumtype=adler32:checksumvalue=2b028a5e: Failed to prepare destination: Fi',\n",
       "       'Failed in data staging: Failed to prepare destination srm:/srm.ndgf.org:8443/srm/managerv2?SFN=/atlas/disk/atlasscratchdisk/rucio/panda/3c/9c/panda.um.user.chelling.mc16d_13TeV.410482.ntuple_minimalInfo_cutFlow_PRW_SFs.log.19926013.000658.log.tgz:checksum',\n",
       "       \"Failed in data staging: Failed reading from source: gsiftp:/dpmdisk08.lhep.unibe.ch:2811/dpmdisk08.lhep.unibe.ch:/mnt/storage1/atlas/2019-08-31/DAOD_HIGG2D1.18987152._000015.pool.root.1.47636729.0 : Can't read from source: globus_ftp_client: the server re\",\n",
       "       'Failed in data staging: Transfer timed out',\n",
       "       'Failed during processing failure; Serious troubles (problems during processing problems)',\n",
       "       \"Failed in data staging: Failed writing to destination: file:/ceph/grid/cache/data/50/04c3c719663afaff4203351997afb9ea456e39 : Can't write to destination: File exists: Failed to create file /ceph/grid/cache/data/50/04c3c719663afaff4203351997afb9ea456e39\",\n",
       "       'Failed in data staging: Failed to prepare destination srm:/dpm.lhep.unibe.ch:8446/srm/managerv2?SFN=/dpm/lhep.unibe.ch/home/atlas/atlasscratchdisk/rucio/panda/ca/16/panda.um.user.pgadow.data15_13TeV.periodG.data.SWWnomTARfix04.EXOT27.grp15_v01_p3841.log.2',\n",
       "       'Condor HoldReason: CREAM error: Transfer failed: globus_ftp_client: the server responded with an error 500 500-Command failed. : globus_gridftp_server_file.c:globus_l_gfs_file_send:3315: 500-globus_l_gfs_file_open failed. 500-globus_gridftp_server_file.c',\n",
       "       'LRMS error: (271)',\n",
       "       'Condor HoldReason: globus_xio: System error in recv: Connection reset by peer globus_xio: A system call failed: Connection reset by peer ; Condor RemoveReason: Python-initiated action. (by user atlpan)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.result['pattern'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "43",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 43",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-57b999983360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PyCharmProjects/ClusterLogs/clusterlogs/pipeline.py\u001b[0m in \u001b[0;36min_cluster\u001b[0;34m(self, groups, cluster_label)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0min_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'indices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3735\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3736\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3737\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 43"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "cluster.in_cluster(cluster.result, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split clusters to big (cluster_size >= 1000) and small (cluster_size < 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big, small = cluster.split_clusters(cluster.result, 'cluster_size', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all messages from cluster #40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.in_cluster(clusters, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the performance of all stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}